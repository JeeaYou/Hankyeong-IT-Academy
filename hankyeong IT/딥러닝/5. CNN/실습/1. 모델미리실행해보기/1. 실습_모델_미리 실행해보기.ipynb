{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d33c3cbb",
   "metadata": {},
   "source": [
    "### 이 작업은\n",
    "- 모델분류성능이 뛰어난 패션mnist.h5 모델이 있다는 가정하에\n",
    "- 28,28,1 의 패션 이미지 자료가 이미지에 있을때\n",
    "- 패션mnist에서 예측한 폴더로 자동 분배하는 코드임 (당근마켓에서 자료 올리면 자동으로 그 폴더로 이동하는 기능임)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282a8569",
   "metadata": {},
   "source": [
    "#### [1] numpy자료를 이미지로 저장하여봄\n",
    "- 패션 이미지를 준비하기 위하여 이러한 방법을 사용해봄...\n",
    "- 흑백 28,28,1 의 이미지가 이미 준비되어 있다면 이 작업은 진행하지 않아도 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45309d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "478fcdc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8f768e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.mkdir('./fashion_img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09a4962d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### fashion_img 폴더에 train_x의 60000장 이미지가 저장됨\n",
    "import imageio\n",
    "for cnt,x in enumerate(X_train):\n",
    "    fileName='fashion_' + str(cnt).zfill(7) + '.jpg'\n",
    "    imageio.imwrite('./fashion_img/' +  fileName, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53f1331",
   "metadata": {},
   "source": [
    "#### [2]패션mnist 모델을 이용하여서 10개의 카테고리로 이미지를 자동으로 배분하고자함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06b5448f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d07af6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 작업할 폴더 제작 (T-shift/top 단어는 폴더명으로 부적합한 -과 / 를 _로 변경함)\n",
    "class_names = ['T_shirt_top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "\n",
    "os.mkdir('./패션이미지종류별로나눔')\n",
    "\n",
    "for x in class_names:\n",
    "    os.mkdir('./패션이미지종류별로나눔/' +  x )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32886bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 13, 13, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 3, 3, 64)          36928     \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 576)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                36928     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "▶ 모델제작된 input size는==>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, 28, 28, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=load_model('./강사제공models/fashionMNIST_CNN.hdf5') \n",
    "model.summary()   \n",
    "# 모델의 가장 상단에 input 사이즈(모델에 입력된 이미지의 크기)를 별도로 레이어로 넣으면 이미지의 사이즈를 알수 있지만\n",
    "# 아래의 모델 summary는 가장 상단에 conv2d 레이어로 input_size를 알수 없음\n",
    "# 그래서 input 사이즈가 있는 레이어로 맨 위를 구성하기도함.\n",
    "# 모델은 있지만 input_size를 summary로도 알수 없는 경우는\n",
    "\n",
    "# 첫번째 레이어의 input_shape을 이용해서 작성된 모델의 입력되는 input사이즈를 알수 있음.\n",
    "print('▶ 모델제작된 input size는==>')\n",
    "model.layers[0].input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7136a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 위의 모델 summary의 마지막 dense값의 2개이상이면 softmax함수를 사용한것임."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f745223d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 샘플로 10개만 확인해봄\n",
    "imgList=glob('./fashion_img/*.jpg')\n",
    "plt.figure(figsize=(20,5))\n",
    "for cnt,x in enumerate(imgList[:10]):\n",
    "    \n",
    "    img=Image.open(x).convert('L') #흑백으로 읽음\n",
    "    img=img.resize((28,28))\n",
    "    imgArr=np.array(img)/255\n",
    "    inputimage=imgArr.reshape(1,28,28,1)\n",
    "    predictNum=model.predict(inputimage)  # 1-1에서 모델제작할때 \n",
    "    num=np.argmax(predictNum)  #3번값이 제일큼\n",
    "    \n",
    "    plt.subplot(1,10,cnt+1)\n",
    "    plt.imshow(imgArr, cmap='gray')\n",
    "    plt.title(class_names[num])\n",
    "    \n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143864bc",
   "metadata": {},
   "source": [
    "#### [3] 최종:\n",
    "- 위의 자료를 보면 결과가 잘 나오고 있음\n",
    "- 위의 예측한 폴더로 저장하려함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7557494c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "model=load_model('./data/model/fashionMNIST_CNN.hdf5') \n",
    "imgList=glob('./fashion_img/*.jpg')\n",
    "\n",
    "for x in imgList:\n",
    "    \n",
    "    img=Image.open(x).convert('L') #흑백으로 읽음\n",
    "    img=img.resize((28,28))\n",
    "    imgArr=np.array(img)/255\n",
    "    inputimage=imgArr.reshape(1,28,28,1)\n",
    "    predictNum=model.predict(inputimage)  # 1-1에서 모델제작할때 \n",
    "    num=np.argmax(predictNum)  #3번값이 제일큼\n",
    "    \n",
    "    imgName=x.split('\\\\')[-1]\n",
    "    sourceFileName='./fashion_img/' + imgName\n",
    "    targetFileName='./패션이미지종류별로나눔/' + class_names[num] + '/' + imgName\n",
    "    shutil.move(sourceFileName,targetFileName)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('han')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "9ffd841040af6bedd50cabf1584399d13f777232c008d7c4ad470663779a547a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
